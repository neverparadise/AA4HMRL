{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kukjin/.conda/envs/darl2/lib/python3.10/site-packages/torchrl/collectors/collectors.py:1086: UserWarning: `devices` keyword argument will soon be deprecated from multiprocessed collectors. Please use `device` instead.\n",
      "  warnings.warn(\n",
      "/home/kukjin/.conda/envs/darl2/lib/python3.10/site-packages/torchrl/collectors/collectors.py:1094: UserWarning: `storing_devices` keyword argument will soon be deprecated from multiprocessed collectors. Please use `storing_device` instead.\n",
      "  warnings.warn(\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kukjin/.conda/envs/darl2/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/kukjin/.conda/envs/darl2/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/kukjin/.conda/envs/darl2/lib/python3.10/site-packages/torchrl/collectors/collectors.py\", line 2014, in _main_async_collector\n",
      "    inner_collector = SyncDataCollector(\n",
      "  File \"/home/kukjin/.conda/envs/darl2/lib/python3.10/site-packages/torchrl/collectors/collectors.py\", line 558, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: A 'truncated' key is already present in the environment and the 'max_frames_per_traj' argument may conflict with a 'StepCounter' that has already been set. Possible solutions: Set max_frames_per_traj to 0 or remove the StepCounter limit from the environment transforms.\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m env_maker2 \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m: TransformedEnv(GymEnv(\u001b[39m\"\u001b[39m\u001b[39mPendulum-v1\u001b[39m\u001b[39m\"\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m), StepCounter(max_steps\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m))\n\u001b[1;32m     10\u001b[0m policy \u001b[39m=\u001b[39m TensorDictModule(nn\u001b[39m.\u001b[39mLinear(\u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m), in_keys\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobservation\u001b[39m\u001b[39m\"\u001b[39m], out_keys\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maction\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m collector \u001b[39m=\u001b[39m MultiSyncDataCollector(\n\u001b[1;32m     12\u001b[0m      create_env_fn\u001b[39m=\u001b[39;49m[env_maker1, env_maker2],\n\u001b[1;32m     13\u001b[0m      policy\u001b[39m=\u001b[39;49mpolicy,\n\u001b[1;32m     14\u001b[0m      total_frames\u001b[39m=\u001b[39;49m\u001b[39m2000\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m      max_frames_per_traj\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m      frames_per_batch\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m      init_random_frames\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     18\u001b[0m      reset_at_each_iter\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     19\u001b[0m      devices\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     20\u001b[0m      storing_devices\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     21\u001b[0m  )\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/site-packages/torchrl/collectors/collectors.py:1216\u001b[0m, in \u001b[0;36m_MultiDataCollector.__init__\u001b[0;34m(self, create_env_fn, policy, frames_per_batch, total_frames, device, storing_device, create_env_kwargs, max_frames_per_traj, init_random_frames, reset_at_each_iter, postproc, split_trajs, exploration_type, exploration_mode, reset_when_done, preemptive_threshold, update_at_each_batch, devices, storing_devices)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreemptive_threshold \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[1;32m   1215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterruptor \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_processes()\n\u001b[1;32m   1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exclude_private_keys \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/site-packages/torchrl/collectors/collectors.py:1288\u001b[0m, in \u001b[0;36m_MultiDataCollector._run_processes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocs\u001b[39m.\u001b[39mappend(proc)\n\u001b[1;32m   1287\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipes\u001b[39m.\u001b[39mappend(pipe_parent)\n\u001b[0;32m-> 1288\u001b[0m msg \u001b[39m=\u001b[39m pipe_parent\u001b[39m.\u001b[39;49mrecv()\n\u001b[1;32m   1289\u001b[0m \u001b[39mif\u001b[39;00m msg \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minstantiated\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1290\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg)\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/multiprocessing/connection.py:250\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 250\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes()\n\u001b[1;32m    251\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39mloads(buf\u001b[39m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_recv_bytes\u001b[39m(\u001b[39mself\u001b[39m, maxsize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv(\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    415\u001b[0m     size, \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m!i\u001b[39m\u001b[39m\"\u001b[39m, buf\u001b[39m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m size \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/multiprocessing/connection.py:383\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    382\u001b[0m     \u001b[39mif\u001b[39;00m remaining \u001b[39m==\u001b[39m size:\n\u001b[0;32m--> 383\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgot end of file during message\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchrl.envs.libs.gym import GymEnv\n",
    "from torchrl.envs import StepCounter\n",
    "from torchrl.collectors import MultiSyncDataCollector\n",
    "from torchrl.envs import TransformedEnv\n",
    "from tensordict.nn import TensorDictModule\n",
    "from torch import nn\n",
    "env_maker1 = lambda: TransformedEnv(GymEnv(\"Pendulum-v1\", device=\"cpu\"), StepCounter(max_steps=50))\n",
    "env_maker2 = lambda: TransformedEnv(GymEnv(\"Pendulum-v1\", device=\"cpu\"), StepCounter(max_steps=50))\n",
    "\n",
    "policy = TensorDictModule(nn.Linear(3, 1), in_keys=[\"observation\"], out_keys=[\"action\"])\n",
    "collector = MultiSyncDataCollector(\n",
    "     create_env_fn=[env_maker1, env_maker2],\n",
    "     policy=policy,\n",
    "     total_frames=2000,\n",
    "     max_frames_per_traj=50,\n",
    "     frames_per_batch=200,\n",
    "     init_random_frames=-1,\n",
    "     reset_at_each_iter=False,\n",
    "     devices=\"cpu\",\n",
    "     storing_devices=\"cpu\",\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(collector):\n",
    "     if i == 2:\n",
    "         print(data)\n",
    "         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'defaults': [{'ppo': 'ppo'}, {'nn': 'nn'}, {'ccnn_img': 'ccnn_img'}, {'ccnn_seq': 'ccnn_seq'}, '_self_'], 'hydra': {'run': {'dir': 'outputs/${now:%Y-%m-%d/%H-%M-%S}'}}, 'experiment': {'env_ids': ['CartPole-v1'], 'seed': 42, 'max_episode_steps': 1000, 'num_rollout_steps': 128, 'num_envs': 64, 'total_timesteps': 10000000, 'save_ckpt': False, 'num_checkpoints': 20, 'print_interval': 100, 'stop_after_epochs': 500, 'capture_video': False, 'device': 0, 'cuda': True, 'torch_deterministic': True, 'resume': False, 'resume_update_idx': 0, 'resume_dir': 'None'}, 'evaluation': {'eval_seed': 3142, 'every': 8, 'num_eval': 5, 'num_test_envs': 5}, 'wandb': {'mode': 'online', 'project': 'DomainAgnosticRL', 'entity': None, 'name': None, 'group': None, 'tags': None, 'notes': None}, 'paths': {'dir': 'outputs/${now:%Y-%m-%d/%H-%M-%S}', 'log': 'outputs/${now:%Y-%m-%d/%H-%M-%S}/runs', 'video': 'outputs/${now:%Y-%m-%d/%H-%M-%S}/videos', 'checkpoints': 'outputs/${now:%Y-%m-%d/%H-%M-%S}/checkpoints', 'src': 'outputs/${now:%Y-%m-%d/%H-%M-%S}/src', 'scripts': 'outputs/${now:%Y-%m-%d/%H-%M-%S}/scripts'}, 'nn': {'actor_critic': {'use_mlp': True, 'use_transformer': True, 'encoder_net_1d': 'rnn', 'encoder_net_2d': 'cnn', 'decoder_net': 'rnn', 'd_model': 256, 'activation': 'tanh', 'optimizer': 'adam', 'gradient_visualization': True, 'input_to_hidden': 'pooling', 'hidden_to_output': 'bmm', 'multivariate_normal': False}, 'mlp': {'depth': 3, 'hidden_dim': 256, 'expansion_factor': 128, 'dropout': 0.2, 'activation': 'gelu'}, 'transformer': {'dropout': 0.2, 'dim_feedforward': 256, 'num_heads': 1, 'num_encoder_layers': 3, 'activation': 'gelu'}, 'cnn': {'kernel_size': 3, 'stride': 1, 'num_layers': 3, 'out_channels': 32}, 'rnn': {'final_activation': 'identity', 'num_layers': 3, 'bias': True}, 's4': {'d_state': 64, 'lr': 0.0001, 'num_layers': 2, 'dropout': 0.2, 'final_activation': 'identity', 'initializer': 'uniform'}, 'weight_decay': {'actor': 0.0, 'critic': 0.0}}, 'ppo': {'actor_lr': 0.00025, 'critic_lr': 0.0005, 'actor_weight_decay': 1e-05, 'critic_weight_decay': 1e-05, 'anneal_lr': False, 'update_epochs': 5, 'num_minibatches': 8, 'batch_size': 'None', 'minibatch_size': 'None', 'max_grad_norm': 0.5, 'norm_adv': True, 'norm_return': False, 'const_coef': 0.0, 'clip_coef': 0.2, 'clip_vloss': True, 'ent_coef': 0.0, 'vf_coef': 0.5, 'gamma': 0.99, 'gae_lambda': 0.95}, 'ccnn_seq': {'net': {'type': 'ResNet', 'no_hidden': 64, 'no_blocks': 2, 'no_stages': -1, 'data_dim': 2, 'dropout': 0.1, 'dropout_in': 0.0, 'dropout_type': 'Dropout2d', 'norm': 'BatchNorm', 'nonlinearity': 'GELU', 'block_width_factors': [0.0], 'block': {'type': 'S4', 'prenorm': True}, 'prenorm': True, 'downsampling': [], 'downsampling_size': -1}, 'kernel': {'type': 'MAGNet', 'bias': True, 'no_hidden': 64, 'no_layers': 2, 'omega_0': 2085.433586112234, 'input_scale': 0.0, 'size': 33, 'chang_initialize': True, 'norm': 'Identity', 'nonlinearity': 'Identity', 'init_spatial_value': 1.0, 'num_edges': -1, 'bottleneck_factor': -1}, 'mask': {'type': 'gaussian', 'init_value': 0.75, 'threshold': 0.1, 'temperature': 0, 'dynamic_cropping': True, 'learn_mean': False}, 'conv': {'bias': True, 'causal': False, 'type': 'SeparableFlexConv', 'use_fft': False, 'padding': 'same', 'stride': 1, 'cache': False}}, 'ccnn_img': {'net': {'type': 'ResNet', 'no_hidden': 32, 'no_blocks': 2, 'no_stages': -1, 'data_dim': 1, 'dropout': 0.1, 'dropout_in': 0.0, 'dropout_type': 'Dropout1d', 'norm': 'BatchNorm', 'nonlinearity': 'GELU', 'block_width_factors': [0.0], 'block': {'type': 'S4', 'prenorm': True}, 'prenorm': True, 'downsampling': [], 'downsampling_size': -1}, 'kernel': {'type': 'MAGNet', 'bias': True, 'no_hidden': 32, 'no_layers': 2, 'omega_0': 976.781, 'input_scale': 0.0, 'size': 33, 'chang_initialize': True, 'norm': 'Identity', 'nonlinearity': 'Identity', 'init_spatial_value': 1.0, 'num_edges': -1, 'bottleneck_factor': -1}, 'mask': {'type': 'gaussian', 'init_value': 0.075, 'threshold': 0.1, 'temperature': 0, 'dynamic_cropping': True, 'learn_mean': False}, 'conv': {'bias': True, 'causal': True, 'type': 'SeparableFlexConv', 'use_fft': True, 'padding': 'same', 'stride': 1, 'cache': False}}}\n"
     ]
    }
   ],
   "source": [
    "from torchrl.envs.libs.gym import GymEnv\n",
    "from torchrl.envs import StepCounter\n",
    "from torchrl.collectors import MultiSyncDataCollector\n",
    "from torchrl.envs import TransformedEnv\n",
    "from tensordict.nn import TensorDictModule\n",
    "import torch\n",
    "from torch import nn\n",
    "from omegaconf import OmegaConf\n",
    "from modules.networks.blocks import get_encoder_1d, get_encoder_2d, get_decoder\n",
    "from modules.networks.mlp import ResidualMLP\n",
    "from modules.utils import get_activation\n",
    "from torch.distributions import Normal, Categorical\n",
    "\n",
    "cfg_path = \"/home/kukjin/kukjin/Projects/MultiEnvRL/DARL_transformer/configs/ppo_trainer.yaml\"\n",
    "nn_cfg_path = \"/home/kukjin/kukjin/Projects/MultiEnvRL/DARL_transformer/configs/nn/nn.yaml\"\n",
    "ppo_cfg_path = \"/home/kukjin/kukjin/Projects/MultiEnvRL/DARL_transformer/configs/ppo/ppo.yaml\"\n",
    "ccnn_cfg_img_path = \"/home/kukjin/kukjin/Projects/MultiEnvRL/DARL_transformer/configs/ccnn_img/ccnn_img.yaml\"\n",
    "ccnn_cfg_seq_path = \"/home/kukjin/kukjin/Projects/MultiEnvRL/DARL_transformer/configs/ccnn_seq/ccnn_seq.yaml\"\n",
    "\n",
    "cfg = OmegaConf.load(cfg_path)\n",
    "nn_cfg = OmegaConf.load(nn_cfg_path)\n",
    "ppo_cfg = OmegaConf.load(ppo_cfg_path)\n",
    "ccnn_seq_cfg = OmegaConf.load(ccnn_cfg_img_path)\n",
    "ccnn_img_cfg = OmegaConf.load(ccnn_cfg_seq_path)\n",
    "\n",
    "cfg.nn = nn_cfg\n",
    "cfg.ppo = ppo_cfg\n",
    "cfg.ccnn_seq = ccnn_seq_cfg\n",
    "cfg.ccnn_img = ccnn_img_cfg\n",
    "\n",
    "print(cfg)\n",
    "\n",
    "def bmm_input(b_weight, b_input):\n",
    "    batch_size, feature_dim = b_input.shape\n",
    "    bmm = torch.einsum('nfh, nf -> nh', b_weight, b_input) / feature_dim\n",
    "    return bmm\n",
    "\n",
    "\n",
    "def bmm_output(b_weight, b_input):\n",
    "    batch_size, output_dim, shared_output_dim = b_weight.shape\n",
    "    batch_size, shared_output_dim = b_input.shape\n",
    "    # [batch_size, 6, 32], [batch_size, 32]\n",
    "    bmm = torch.einsum('noh, nh -> no', b_weight, b_input)  / shared_output_dim\n",
    "    return bmm\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, cfg: OmegaConf):\n",
    "        super().__init__()\n",
    "        activation_name = cfg.nn.actor_critic.activation\n",
    "        self.act_func = get_activation(activation_name)()\n",
    "        self.obs_encoder_1d = get_encoder_1d(cfg)\n",
    "        self.policy_prob_decoder = get_decoder(cfg)\n",
    "        self.input_to_hidden = cfg.nn.actor_critic.input_to_hidden\n",
    "        self.hidden_to_output = cfg.nn.actor_critic.hidden_to_output\n",
    "        self.use_mlp = cfg.nn.actor_critic.use_mlp\n",
    "        if self.use_mlp:\n",
    "            self.res_mlp = ResidualMLP(cfg)\n",
    "    \n",
    "    def forward(self, is_continuous, output_dim, x):\n",
    "        print(f\"is_continuous: {is_continuous}\")\n",
    "        print(f\"output_dim: {output_dim}\")\n",
    "        \n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "            is_continuous = is_continuous.unsqueeze(0)\n",
    "            output_dim = output_dim.unsqueeze(0)\n",
    "            \n",
    "        # x: [batch_size, feature_dim]\n",
    "        # ? Encoding\n",
    "        h = self.get_hidden_from_1d_bmm(x)\n",
    "        # h: [batch_size, d_model]\n",
    "        h = self.act_func(h) \n",
    "        # ? Shared MLP\n",
    "        if self.use_mlp:\n",
    "            h = self.act_func(self.res_mlp(h))\n",
    "        # ? Decoding\n",
    "        dist, _ = self.get_dist_with_bmm(is_continuous, output_dim, h)\n",
    "        return dist.sample()\n",
    "    \n",
    "    def get_hidden_from_1d_bmm(self, x):\n",
    "        h = self.obs_encoder_1d(x)\n",
    "        h = bmm_input(h, x)\n",
    "        return h\n",
    "    \n",
    "    def get_dist_with_bmm(self, is_continuous, output_dim, h):\n",
    "        out_dim = output_dim[0]\n",
    "        if is_continuous[0]:\n",
    "            a_mean_weights = self.policy_mean_decoder(out_dim, h)\n",
    "            a_logstd_weights = self.policy_logstd_decoder(out_dim, h)\n",
    "            # a_mean_weights, a_logstd_weights: [batch_size, act_dim, d_model]\n",
    "            a_mu = bmm_output(a_mean_weights, h) # out: [batch_size, act_dim]\n",
    "            a_logstd = bmm_output(a_logstd_weights, h) # out: [batch_size, act_dim]\n",
    "            a_logstd = torch.tanh(a_logstd)\n",
    "            a_logstd = self.LOG_STD_MIN + 0.5 * (self.LOG_STD_MAX - self.LOG_STD_MIN) * (a_logstd + 1)\n",
    "            actor_std = a_logstd.exp()\n",
    "            dist = Normal(a_mu, actor_std)\n",
    "            return dist, a_mu\n",
    "        else:\n",
    "            # generate policy weights\n",
    "            a_probs_weight = self.policy_prob_decoder(out_dim, h)\n",
    "            self.policy_prob_weights = a_probs_weight\n",
    "            logits = bmm_output(a_probs_weight, h) # out: [batch_size, act_dim]\n",
    "            # get categorical distribution\n",
    "            dist = Categorical(logits=logits)\n",
    "            return dist, logits\n",
    "        \n",
    "actor = Actor(cfg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        is_continuous: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        output_dim: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchrl.envs.libs.gym import GymEnv\n",
    "env = GymEnv(\"CartPole-v1\", device=\"cpu\")\n",
    "td = env.reset()\n",
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tensordict.nn import TensorDictModule\n",
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "from torch import nn\n",
    "\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "from torchrl.envs import (\n",
    "    Compose,\n",
    "    DoubleToFloat,\n",
    "    ObservationNorm,\n",
    "    StepCounter,\n",
    "    TransformedEnv,\n",
    ")\n",
    "from torchrl.envs.libs.gym import GymEnv\n",
    "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type\n",
    "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
    "from torchrl.objectives import ClipPPOLoss\n",
    "from torchrl.objectives.value import GAE\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = TensorDictModule(actor, in_keys=[\"is_continuous\", \"output_dim\", \"observation\"], out_keys=[\"action\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_continuous: False\n",
      "output_dim: tensor([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        is_continuous: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        output_dim: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_continuous: False\n",
      "output_dim: tensor([2])\n"
     ]
    }
   ],
   "source": [
    "td['action'] = policy(td)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug 1\n",
      "TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        is_continuous: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        output_dim: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "is_continuous: None\n",
      "output_dim: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kukjin/.conda/envs/darl2/lib/python3.10/site-packages/torchrl/collectors/collectors.py:574: UserWarning: total_frames (200) is not exactly divisible by frames_per_batch (32).This means 24 additional frames will be collected.To silence this message, set the environment variable RL_WARNINGS to False.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Some tensors that are necessary for the module call may not have not been found in the input tensordict: the following inputs are None: {'output_dim', 'is_continuous'}.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/site-packages/tensordict/nn/common.py:798\u001b[0m, in \u001b[0;36mTensorDictModule.forward\u001b[0;34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 798\u001b[0m     tensors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_module(tensors, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    799\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/site-packages/tensordict/nn/common.py:766\u001b[0m, in \u001b[0;36mTensorDictModule._call_module\u001b[0;34m(self, tensors, **kwargs)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_module\u001b[39m(\n\u001b[1;32m    764\u001b[0m     \u001b[39mself\u001b[39m, tensors: Sequence[Tensor], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[1;32m    765\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor \u001b[39m|\u001b[39m Sequence[Tensor]:\n\u001b[0;32m--> 766\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule(\u001b[39m*\u001b[39;49mtensors, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    767\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/site-packages/tensordict/nn/functional_modules.py:431\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 431\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mtype\u001b[39;49m(\u001b[39mself\u001b[39;49m), fun_name)(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "Cell \u001b[0;32mIn[9], line 65\u001b[0m, in \u001b[0;36mActor.forward\u001b[0;34m(self, is_continuous, output_dim, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m is_continuous \u001b[39m=\u001b[39m is_continuous\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     66\u001b[0m output_dim \u001b[39m=\u001b[39m output_dim\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'unsqueeze'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m collector \u001b[39m=\u001b[39m SyncDataCollector(\n\u001b[1;32m      2\u001b[0m     env,\n\u001b[1;32m      3\u001b[0m     policy,\n\u001b[1;32m      4\u001b[0m     frames_per_batch\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     total_frames\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     split_trajs\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m      7\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/site-packages/torchrl/collectors/collectors.py:659\u001b[0m, in \u001b[0;36mSyncDataCollector.__init__\u001b[0;34m(self, create_env_fn, policy, frames_per_batch, total_frames, device, storing_device, create_env_kwargs, max_frames_per_traj, init_random_frames, reset_at_each_iter, postproc, split_trajs, exploration_type, exploration_mode, return_same_td, reset_when_done, interruptor)\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    658\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensordict_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensordict_out\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 659\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensordict_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tensordict_out)\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensordict_out \u001b[39m=\u001b[39m (\n\u001b[1;32m    661\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensordict_out\u001b[39m.\u001b[39mexpand(\u001b[39m*\u001b[39menv\u001b[39m.\u001b[39mbatch_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframes_per_batch)\n\u001b[1;32m    662\u001b[0m         \u001b[39m.\u001b[39mclone()\n\u001b[1;32m    663\u001b[0m         \u001b[39m.\u001b[39mzero_()\n\u001b[1;32m    664\u001b[0m     )\n\u001b[1;32m    665\u001b[0m \u001b[39m# in addition to outputs of the policy, we add traj_ids and step_count to\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[39m# _tensordict_out which will be collected during rollout\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/site-packages/tensordict/nn/functional_modules.py:431\u001b[0m, in \u001b[0;36m_make_decorator.<locals>.new_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    430\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 431\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mtype\u001b[39;49m(\u001b[39mself\u001b[39;49m), fun_name)(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    432\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    433\u001b[0m         pattern \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.*takes \u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+ positional arguments but \u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+ were given|got multiple values for argument\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/site-packages/tensordict/nn/common.py:273\u001b[0m, in \u001b[0;36mdispatch.__call__.<locals>.wrapper\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(out[key] \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m dest)\n\u001b[1;32m    272\u001b[0m     \u001b[39mreturn\u001b[39;00m out[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m out\n\u001b[0;32m--> 273\u001b[0m \u001b[39mreturn\u001b[39;00m func(_self, tensordict, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/site-packages/tensordict/_contextlib.py:126\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    125\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 126\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/site-packages/tensordict/nn/utils.py:253\u001b[0m, in \u001b[0;36mset_skip_existing.__call__.<locals>.wrapper\u001b[0;34m(_self, tensordict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    248\u001b[0m     skip_existing()\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(key \u001b[39min\u001b[39;00m tensordict\u001b[39m.\u001b[39mkeys(\u001b[39mTrue\u001b[39;00m) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m out_keys)\n\u001b[1;32m    250\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(key \u001b[39min\u001b[39;00m out_keys \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m in_keys)\n\u001b[1;32m    251\u001b[0m ):\n\u001b[1;32m    252\u001b[0m     \u001b[39mreturn\u001b[39;00m tensordict\n\u001b[0;32m--> 253\u001b[0m \u001b[39mreturn\u001b[39;00m func(_self, tensordict, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/site-packages/tensordict/nn/common.py:804\u001b[0m, in \u001b[0;36mTensorDictModule.forward\u001b[0;34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(tensor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m tensors) \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n\u001b[1;32m    801\u001b[0m     none_set \u001b[39m=\u001b[39m {\n\u001b[1;32m    802\u001b[0m         key \u001b[39mfor\u001b[39;00m key, tensor \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_keys, tensors) \u001b[39mif\u001b[39;00m tensor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    803\u001b[0m     }\n\u001b[0;32m--> 804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m    805\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSome tensors that are necessary for the module call may \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    806\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot have not been found in the input tensordict: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    807\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthe following inputs are None: \u001b[39m\u001b[39m{\u001b[39;00mnone_set\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    808\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    809\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    810\u001b[0m     \u001b[39mraise\u001b[39;00m err\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Some tensors that are necessary for the module call may not have not been found in the input tensordict: the following inputs are None: {'output_dim', 'is_continuous'}.\""
     ]
    }
   ],
   "source": [
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy,\n",
    "    frames_per_batch=32,\n",
    "    total_frames=200,\n",
    "    split_trajs=False,\n",
    "    device='cpu',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kukjin/.conda/envs/darl2/lib/python3.10/site-packages/torchrl/collectors/collectors.py:1086: UserWarning: `devices` keyword argument will soon be deprecated from multiprocessed collectors. Please use `device` instead.\n",
      "  warnings.warn(\n",
      "/home/kukjin/.conda/envs/darl2/lib/python3.10/site-packages/torchrl/collectors/collectors.py:1094: UserWarning: `storing_devices` keyword argument will soon be deprecated from multiprocessed collectors. Please use `storing_device` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "env must be provided to _get_policy_and_device if policy is None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m policy \u001b[39m=\u001b[39m TensorDictModule(actor, in_keys\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mis_continuous\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moutput_dim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mobservation\u001b[39m\u001b[39m\"\u001b[39m], out_keys\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maction\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[39m# policy = TensorDictModule(nn.Linear(3, 1), in_keys=[\"observation\"], out_keys=[\"action\"])\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m collector \u001b[39m=\u001b[39m MultiSyncDataCollector(\n\u001b[1;32m      9\u001b[0m     create_env_fn\u001b[39m=\u001b[39;49m[env_maker1, env_maker2],\n\u001b[1;32m     10\u001b[0m     policy\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     11\u001b[0m     total_frames\u001b[39m=\u001b[39;49m\u001b[39m2000\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     max_frames_per_traj\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m     frames_per_batch\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m     init_random_frames\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m     reset_at_each_iter\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     16\u001b[0m     devices\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m     storing_devices\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(collector):\n\u001b[1;32m     21\u001b[0m     \u001b[39mprint\u001b[39m(data)\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/site-packages/torchrl/collectors/collectors.py:1141\u001b[0m, in \u001b[0;36m_MultiDataCollector.__init__\u001b[0;34m(self, create_env_fn, policy, frames_per_batch, total_frames, device, storing_device, create_env_kwargs, max_frames_per_traj, init_random_frames, reset_at_each_iter, postproc, split_trajs, exploration_type, exploration_mode, reset_when_done, preemptive_threshold, update_at_each_batch, devices, storing_devices)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[39mexcept\u001b[39;00m:  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         observation_spec \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m _policy, _device, _get_weight_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_policy_and_device(\n\u001b[1;32m   1142\u001b[0m     policy\u001b[39m=\u001b[39;49mpolicy, device\u001b[39m=\u001b[39;49m_device, observation_spec\u001b[39m=\u001b[39;49mobservation_spec\n\u001b[1;32m   1143\u001b[0m )\n\u001b[1;32m   1144\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy_dict[_device] \u001b[39m=\u001b[39m _policy\n\u001b[1;32m   1145\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(_policy, nn\u001b[39m.\u001b[39mModule):\n",
      "File \u001b[0;32m~/.conda/envs/darl2/lib/python3.10/site-packages/torchrl/collectors/collectors.py:208\u001b[0m, in \u001b[0;36mDataCollectorBase._get_policy_and_device\u001b[0;34m(self, policy, device, observation_spec)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mif\u001b[39;00m policy \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39menv\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    209\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39menv must be provided to _get_policy_and_device if policy is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m         )\n\u001b[1;32m    211\u001b[0m     policy \u001b[39m=\u001b[39m RandomPolicy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39maction_spec)\n\u001b[1;32m    212\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(policy, nn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m    213\u001b[0m     \u001b[39m# TODO: revisit these checks when we have determined whether arbitrary\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# callables should be supported as policies.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: env must be provided to _get_policy_and_device if policy is None"
     ]
    }
   ],
   "source": [
    "env_maker1 = lambda: TransformedEnv(GymEnv(\"Pendulum-v1\", device=\"cpu\"))\n",
    "env_maker2 = lambda: TransformedEnv(GymEnv(\"HalfCheetah-v4\", device=\"cpu\"))\n",
    "# env_maker2 = lambda: TransformedEnv(GymEnv(\"Pendulum-v1\", device=\"cpu\"))\n",
    "\n",
    "policy = TensorDictModule(actor, in_keys=[\"is_continuous\", \"output_dim\", \"observation\"], out_keys=[\"action\"])\n",
    "# policy = TensorDictModule(nn.Linear(3, 1), in_keys=[\"observation\"], out_keys=[\"action\"])\n",
    "\n",
    "collector = MultiSyncDataCollector(\n",
    "    create_env_fn=[env_maker1, env_maker2],\n",
    "    policy=None,\n",
    "    total_frames=100,\n",
    "    max_frames_per_traj=50,\n",
    "    frames_per_batch=64,\n",
    "    init_random_frames=-1,\n",
    "    reset_at_each_iter=False,\n",
    "    devices=\"cpu\",\n",
    "    storing_devices=\"cpu\",\n",
    ")\n",
    "\n",
    "for i, data in enumerate(collector):\n",
    "    print(data)\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9e147bd2cac9f8cba0aaeac8e3aa69463602115a7ce7416575bcd10d62ea995"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
