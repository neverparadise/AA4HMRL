{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tensordict.tensordict import TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3, 4)\n",
    "b = torch.rand(3, 4, 5)\n",
    "tensordict = TensorDict({\"a\": a, \"b\": b}, batch_size=[3, 4])\n",
    "\n",
    "indexed_tensordict = tensordict[:2, 1]\n",
    "assert indexed_tensordict[\"a\"].shape == torch.Size([2])\n",
    "assert indexed_tensordict[\"b\"].shape == torch.Size([2, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(shape=torch.Size([1, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        b: Tensor(shape=torch.Size([1, 4, 5]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([1, 4]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(shape=torch.Size([2, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        b: Tensor(shape=torch.Size([2, 4, 5]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([2, 4]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(shape=torch.Size([3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        b: Tensor(shape=torch.Size([3, 2, 5]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([3, 2]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8008, 0.1869, 0.8878, 0.8746],\n",
      "        [0.8891, 0.7147, 0.2167, 0.9934],\n",
      "        [0.5049, 0.3155, 0.7060, 0.9949]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tensordict[:, :]['a'])\n",
    "tensordict[:, :]['b'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kukjin/.conda/envs/darl2/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n"
     ]
    }
   ],
   "source": [
    "import envpool\n",
    "from modules.utils import set_seed, make_batched_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'defaults': [{'ppo': 'ppo'}, {'nn': 'nn'}, {'ccnn_img': 'ccnn_img'}, {'ccnn_seq': 'ccnn_seq'}, '_self_'], 'hydra': {'run': {'dir': 'outputs/${now:%Y-%m-%d/%H-%M-%S}'}}, 'experiment': {'env_ids': ['CartPole-v1'], 'seed': 42, 'max_episode_steps': 1000, 'num_rollout_steps': 128, 'num_envs': 64, 'total_timesteps': 10000000, 'save_ckpt': False, 'num_checkpoints': 20, 'print_interval': 100, 'stop_after_epochs': 500, 'capture_video': False, 'device': 1, 'cuda': True, 'torch_deterministic': True, 'resume': False, 'resume_update_idx': 0, 'resume_dir': 'None'}, 'evaluation': {'eval_seed': 3142, 'every': 8, 'num_eval': 5, 'num_test_envs': 5}, 'wandb': {'mode': 'online', 'project': 'DomainAgnosticRL', 'entity': None, 'name': None, 'group': None, 'tags': None, 'notes': None}, 'paths': {'dir': 'outputs/${now:%Y-%m-%d/%H-%M-%S}', 'log': 'outputs/${now:%Y-%m-%d/%H-%M-%S}/runs', 'video': 'outputs/${now:%Y-%m-%d/%H-%M-%S}/videos', 'checkpoints': 'outputs/${now:%Y-%m-%d/%H-%M-%S}/checkpoints', 'src': 'outputs/${now:%Y-%m-%d/%H-%M-%S}/src', 'scripts': 'outputs/${now:%Y-%m-%d/%H-%M-%S}/scripts'}, 'nn': {'actor_critic': {'use_mlp': True, 'use_transformer': True, 'encoder_net_1d': 'rnn', 'encoder_net_2d': 'cnn', 'decoder_net': 'rnn', 'd_model': 128, 'activation': 'tanh', 'optimizer': 'adam', 'gradient_visualization': True, 'input_to_hidden': 'pooling', 'hidden_to_output': 'bmm', 'multivariate_normal': False}, 'mlp': {'depth': 1, 'hidden_dim': 256, 'expansion_factor': 128, 'dropout': 0.0, 'activation': 'gelu'}, 'transformer': {'dropout': 0.0, 'dim_feedforward': 128, 'num_heads': 1, 'num_encoder_layers': 1, 'activation': 'gelu'}, 'cnn': {'kernel_size': 3, 'stride': 1, 'num_layers': 3, 'out_channels': 32}, 'rnn': {'final_activation': 'identity', 'num_layers': 1, 'bias': True}, 's4': {'d_state': 64, 'lr': 0.0001, 'num_layers': 2, 'dropout': 0.0, 'final_activation': 'identity', 'initializer': 'uniform'}, 'weight_decay': {'actor': 0.0, 'critic': 0.0}}, 'ppo': {'actor_lr': 0.00025, 'critic_lr': 0.0005, 'actor_weight_decay': 1e-05, 'critic_weight_decay': 1e-05, 'anneal_lr': False, 'update_epochs': 5, 'num_minibatches': 8, 'batch_size': 'None', 'minibatch_size': 'None', 'max_grad_norm': 0.5, 'norm_adv': True, 'norm_return': False, 'const_coef': 0.0, 'clip_coef': 0.2, 'clip_vloss': True, 'ent_coef': 0.0, 'vf_coef': 0.5, 'gamma': 0.99, 'gae_lambda': 0.95}, 'ccnn_seq': {'net': {'type': 'ResNet', 'no_hidden': 64, 'no_blocks': 2, 'no_stages': -1, 'data_dim': 2, 'dropout': 0.1, 'dropout_in': 0.0, 'dropout_type': 'Dropout2d', 'norm': 'BatchNorm', 'nonlinearity': 'GELU', 'block_width_factors': [0.0], 'block': {'type': 'S4', 'prenorm': True}, 'prenorm': True, 'downsampling': [], 'downsampling_size': -1}, 'kernel': {'type': 'MAGNet', 'bias': True, 'no_hidden': 64, 'no_layers': 2, 'omega_0': 2085.433586112234, 'input_scale': 0.0, 'size': 33, 'chang_initialize': True, 'norm': 'Identity', 'nonlinearity': 'Identity', 'init_spatial_value': 1.0, 'num_edges': -1, 'bottleneck_factor': -1}, 'mask': {'type': 'gaussian', 'init_value': 0.75, 'threshold': 0.1, 'temperature': 0, 'dynamic_cropping': True, 'learn_mean': False}, 'conv': {'bias': True, 'causal': False, 'type': 'SeparableFlexConv', 'use_fft': False, 'padding': 'same', 'stride': 1, 'cache': False}}, 'ccnn_img': {'net': {'type': 'ResNet', 'no_hidden': 32, 'no_blocks': 2, 'no_stages': -1, 'data_dim': 1, 'dropout': 0.1, 'dropout_in': 0.0, 'dropout_type': 'Dropout1d', 'norm': 'BatchNorm', 'nonlinearity': 'GELU', 'block_width_factors': [0.0], 'block': {'type': 'S4', 'prenorm': True}, 'prenorm': True, 'downsampling': [], 'downsampling_size': -1}, 'kernel': {'type': 'MAGNet', 'bias': True, 'no_hidden': 32, 'no_layers': 2, 'omega_0': 976.781, 'input_scale': 0.0, 'size': 33, 'chang_initialize': True, 'norm': 'Identity', 'nonlinearity': 'Identity', 'init_spatial_value': 1.0, 'num_edges': -1, 'bottleneck_factor': -1}, 'mask': {'type': 'gaussian', 'init_value': 0.075, 'threshold': 0.1, 'temperature': 0, 'dynamic_cropping': True, 'learn_mean': False}, 'conv': {'bias': True, 'causal': True, 'type': 'SeparableFlexConv', 'use_fft': True, 'padding': 'same', 'stride': 1, 'cache': False}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "cfg_path = \"/home/kukjin/kukjin/Projects/MultiEnvRL/DARL_transformer/configs/ppo_trainer.yaml\"\n",
    "nn_cfg_path = \"/home/kukjin/kukjin/Projects/MultiEnvRL/DARL_transformer/configs/nn/nn.yaml\"\n",
    "ppo_cfg_path = \"/home/kukjin/kukjin/Projects/MultiEnvRL/DARL_transformer/configs/ppo/ppo.yaml\"\n",
    "ccnn_cfg_img_path = \"/home/kukjin/kukjin/Projects/MultiEnvRL/DARL_transformer/configs/ccnn_img/ccnn_img.yaml\"\n",
    "ccnn_cfg_seq_path = \"/home/kukjin/kukjin/Projects/MultiEnvRL/DARL_transformer/configs/ccnn_seq/ccnn_seq.yaml\"\n",
    "\n",
    "cfg = OmegaConf.load(cfg_path)\n",
    "nn_cfg = OmegaConf.load(nn_cfg_path)\n",
    "ppo_cfg = OmegaConf.load(ppo_cfg_path)\n",
    "ccnn_seq_cfg = OmegaConf.load(ccnn_cfg_img_path)\n",
    "ccnn_img_cfg = OmegaConf.load(ccnn_cfg_seq_path)\n",
    "\n",
    "cfg.nn = nn_cfg\n",
    "cfg.ppo = ppo_cfg\n",
    "cfg.ccnn_seq = ccnn_seq_cfg\n",
    "cfg.ccnn_img = ccnn_img_cfg\n",
    "\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train env 1: CartPole-v1 is loaded\n",
      "1/2environment CartPole-v1 is loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kukjin/.conda/envs/darl2/lib/python3.10/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/kukjin/.conda/envs/darl2/lib/python3.10/site-packages/gym/spaces/box.py:128: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train env 2: HalfCheetah-v4 is loaded\n",
      "2/2environment HalfCheetah-v4 is loaded...\n"
     ]
    }
   ],
   "source": [
    "env_ids = [\"CartPole-v1\", \"HalfCheetah-v4\"]\n",
    "train_different_envs = []\n",
    "for j, env_id in enumerate(env_ids):\n",
    "    train_envs = make_batched_env(j, env_id, cfg, mode='train')\n",
    "    train_different_envs.append(train_envs)\n",
    "    print(f\"{j+1}/{len(env_ids)}environment {env_id} is loaded...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "envs_storages = TensorDict({}, batch_size=[128, 64])\n",
    "for i, envs in enumerate(train_different_envs):\n",
    "    env_id = env_ids[i]\n",
    "    obs = torch.zeros((128, 64) \\\n",
    "        + envs.single_observation_space.shape).to(device)\n",
    "    actions = torch.zeros((128, 64) \\\n",
    "        + envs.single_action_space.shape).to(device)\n",
    "    logprobs = torch.zeros((128, 64)).to(device)\n",
    "    rewards = torch.zeros((128, 64)).to(device)\n",
    "    dones = torch.zeros((128, 64)).to(device)\n",
    "    values = torch.zeros((128, 64)).to(device)\n",
    "    storage = TensorDict({\n",
    "                \"obs\": obs,\n",
    "                \"actions\": actions,\n",
    "                \"logprobs\": logprobs,\n",
    "                \"rewards\": rewards,\n",
    "                \"dones\": dones,\n",
    "                \"values\": values\n",
    "                }, batch_size=[128, 64])\n",
    "    envs_storages[env_id] = storage\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        CartPole-v1: TensorDict(\n",
       "            fields={\n",
       "                actions: Tensor(shape=torch.Size([128, 64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                dones: Tensor(shape=torch.Size([128, 64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                logprobs: Tensor(shape=torch.Size([128, 64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                obs: Tensor(shape=torch.Size([128, 64, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                rewards: Tensor(shape=torch.Size([128, 64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                values: Tensor(shape=torch.Size([128, 64]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([128, 64]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        HalfCheetah-v4: TensorDict(\n",
       "            fields={\n",
       "                actions: Tensor(shape=torch.Size([128, 64, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                dones: Tensor(shape=torch.Size([128, 64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                logprobs: Tensor(shape=torch.Size([128, 64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                obs: Tensor(shape=torch.Size([128, 64, 17]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                rewards: Tensor(shape=torch.Size([128, 64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                values: Tensor(shape=torch.Size([128, 64]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([128, 64]),\n",
       "            device=None,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([128, 64]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envs_storages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_storages = envs_storages.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        CartPole-v1: TensorDict(\n",
       "            fields={\n",
       "                actions: Tensor(shape=torch.Size([8192]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                dones: Tensor(shape=torch.Size([8192]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                logprobs: Tensor(shape=torch.Size([8192]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                obs: Tensor(shape=torch.Size([8192, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                rewards: Tensor(shape=torch.Size([8192]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                values: Tensor(shape=torch.Size([8192]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([8192]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        HalfCheetah-v4: TensorDict(\n",
       "            fields={\n",
       "                actions: Tensor(shape=torch.Size([8192, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                dones: Tensor(shape=torch.Size([8192]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                logprobs: Tensor(shape=torch.Size([8192]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                obs: Tensor(shape=torch.Size([8192, 17]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                rewards: Tensor(shape=torch.Size([8192]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                values: Tensor(shape=torch.Size([8192]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([8192]),\n",
       "            device=None,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([8192]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_storages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumTensorDict(TensorDict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def __add__(self, other_dict):\n",
    "        new_dict = SumTensorDict({}, batch_size=self._batch_size)    \n",
    "        assert len(self._tensordict.keys()) == len(other_dict.keys())\n",
    "        for key in self._tensordict.keys():\n",
    "            if not (key in other_dict.keys()):\n",
    "                raise KeyError\n",
    "            new_dict[key] = self._tensordict[key] + other_dict[key]\n",
    "        return new_dict\n",
    "    \n",
    "    def __sub__(self, other_dict):\n",
    "        new_dict = SumTensorDict({}, batch_size=self._batch_size)    \n",
    "        assert len(self._tensordict.keys()) == len(other_dict.keys())\n",
    "        for key in self._tensordict.keys():\n",
    "            if not (key in other_dict.keys()):\n",
    "                raise KeyError\n",
    "            if self._tensordict[key].shape != other_dict[key].shape:\n",
    "                raise ValueError\n",
    "            new_dict[key] = self._tensordict[key] - other_dict[key]\n",
    "        return new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartpole_dict = SumTensorDict({'reward': 0.5*torch.ones([128,]),\n",
    "                               'action': -1*torch.ones([128,]),\n",
    "                               }, batch_size=128)\n",
    "hafcheetah_dict = SumTensorDict({'reward': torch.ones([128,]),\n",
    "                               'action': 2*torch.ones([128,]),\n",
    "                                 }, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_TensorDictKeysView(['reward', 'action'],\n",
      "    include_nested=False,\n",
      "    leaves_only=False)\n",
      "_TensorDictKeysView(['reward', 'action'],\n",
      "    include_nested=False,\n",
      "    leaves_only=False)\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(cartpole_dict.keys())\n",
    "print(hafcheetah_dict.keys())\n",
    "print(len(cartpole_dict.keys()))\n",
    "print(len(hafcheetah_dict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cartpole_dict = TensorDict({'reward': torch.zeros([128,])}, batch_size=128)\n",
    "# hafcheetah_dict = TensorDict({'reward': torch.ones([128,])}, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TensorDict({'reward': []}, batch_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td['reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_dict = cartpole_dict + hafcheetah_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        reward: Tensor(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([128]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cartpole_dict[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'TensorDict' and 'TensorDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sum_dict2 \u001b[39m=\u001b[39m cartpole_dict[:] \u001b[39m+\u001b[39;49m hafcheetah_dict[:]\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'TensorDict' and 'TensorDict'"
     ]
    }
   ],
   "source": [
    "sum_dict2 = cartpole_dict[:] + hafcheetah_dict[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        reward: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([3]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_dict[0:3] # 딕셔너리 키의 값들을 인덱싱 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
       "        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
       "        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
       "        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
       "        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
       "        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
       "        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
       "        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
       "        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
       "        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
       "        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
       "        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
       "        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
       "        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
       "        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
       "        -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtract_dict = cartpole_dict - hafcheetah_dict\n",
    "subtract_dict['reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000,\n",
       "        1.5000, 1.5000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_dict['reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SumTensorDict(\n",
       "    fields={\n",
       "        reward: Tensor(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([128]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TensorDict({}, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data.tensor_specs import CompositeSpec, BoundedTensorSpec, DiscreteTensorSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_vector_spec = BoundedTensorSpec(-torch.ones(17),torch.ones(17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_vector_spec.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(\n",
       "     shape=torch.Size([6]), space=ContinuousBox(minimum=Tensor(shape=torch.Size([6]), device=cpu, dtype=torch.float32, contiguous=True), maximum=Tensor(shape=torch.Size([6]), device=cpu, dtype=torch.float32, contiguous=True)), device=cpu, dtype=torch.float32, domain=continuous)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_vector_spec = BoundedTensorSpec(-torch.ones(6),torch.ones(6))\n",
    "action_vector_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n",
      "continuous\n"
     ]
    }
   ],
   "source": [
    "print(action_vector_spec.shape)\n",
    "print(action_vector_spec.domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiscreteTensorSpec(\n",
       "     shape=torch.Size([1]), space=DiscreteBox(n=2), device=cpu, dtype=torch.int64, domain=discrete)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_vector_spec = DiscreteTensorSpec(2, shape=(1,))\n",
    "action_vector_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs.libs.gym import GymEnv\n",
    "env = GymEnv(\"CartPole-v1\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CartPole-v1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.env_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotDiscreteTensorSpec(\n",
       "     shape=torch.Size([2]), space=DiscreteBox(n=2), device=cpu, dtype=torch.int64, domain=discrete)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_spec.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        is_continuous: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        output_dim: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs['action'] = env.action_spec.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = env.step(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        is_continuous: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        output_dim: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs['env_index'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        env_index: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'discrete'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_spec.domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs['is_continuous'] = False\n",
    "obs['output_dim'] = env.action_spec.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        env_index: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        is_continuous: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        output_dim: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(action_vector_spec.shape)\n",
    "print(action_vector_spec.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d0f7c561fd4fddb74f77a98fc61421c3dd937e1d9d3174b2ba2cda973dab991"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
