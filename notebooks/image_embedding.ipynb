{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_init(layer:torch.nn.Module,\n",
    "               std=np.sqrt(2), \n",
    "               bias_const=0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)\n",
    "    # torch.nn.init.normal_(layer.weight, std)\n",
    "    # torch.nn.init.normal_(layer.bias, std)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # TODO\n",
    "    kernel_size = 3\n",
    "    stride = 1\n",
    "    in_channels = 144\n",
    "    mid_channels = 128\n",
    "    final_channels = 256\n",
    "    num_layers = 3\n",
    "    self.leakyrelu = nn.LeakyReLU()\n",
    "    self.first_block = nn.Sequential(\n",
    "          layer_init(nn.Conv2d(in_channels, mid_channels, kernel_size=kernel_size, stride=stride,\n",
    "                            padding=1, bias=True)),\n",
    "          nn.BatchNorm2d(mid_channels),\n",
    "          nn.GELU())\n",
    "    \n",
    "    self.conv_layers = nn.ModuleList()\n",
    "    self.channels = [mid_channels for i in range(num_layers)]\n",
    "    for i in range(num_layers):  \n",
    "        conv_block = nn.Sequential(\n",
    "                                layer_init(nn.Conv2d(mid_channels, mid_channels, kernel_size=kernel_size, stride=stride,\n",
    "                                padding=1, bias=True)),\n",
    "                                nn.BatchNorm2d(mid_channels),\n",
    "                                nn.GELU())\n",
    "        self.conv_layers.append(conv_block)\n",
    "    self.is_avg_pooling = True\n",
    "    self.final_block = nn.Sequential(\n",
    "            nn.Conv2d(mid_channels, final_channels, kernel_size=kernel_size, stride=stride,\n",
    "                            padding=1, bias=True),\n",
    "            nn.BatchNorm2d(final_channels),\n",
    "            nn.GELU())\n",
    "    self.avg_pooling = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "    input_size = 14 * 14\n",
    "    self.fc = layer_init(nn.Linear(input_size, 256))\n",
    "\n",
    "  def forward(self, x):\n",
    "    if len(x.shape) < 4:\n",
    "      x = x.unsqueeze(0)\n",
    "    x = self.first_block(x)\n",
    "    shortcut = x\n",
    "    for conv_block in self.conv_layers:\n",
    "      x = conv_block(x)\n",
    "      x += shortcut\n",
    "      shortcut = x\n",
    "    # x = self.final_block(x)\n",
    "    # x = self.avg_pooling(x)\n",
    "    # x = x.view(x.size(0), -1)\n",
    "    x = x.view(x.size(0), x.size(1), -1)\n",
    "    x = self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embed_net = Resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "955904"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_params = 0\n",
    "for name, p in image_embed_net.named_parameters():\n",
    "    total_num_params += p.numel()\n",
    "total_num_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_embedding(image_embed_net, image: torch.Tensor):\n",
    "    # image: [batch_size, 4, 84, 84]\n",
    "    patch_width_height = (14, 14)\n",
    "    batch_size = image.size(0)\n",
    "    image = image.to(dtype=torch.float32) / 255.0\n",
    "    image = image.reshape(batch_size, -1, *patch_width_height)\n",
    "    # [32, 144, 14, 14]\n",
    "    print(image.shape)\n",
    "    embed = image_embed_net(image)\n",
    "    return embed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 144, 14, 14])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 256])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.randn([32, 4, 84, 84])\n",
    "embed = image_embedding(image_embed_net, image)\n",
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HMRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8719e50d026025b94f58105440f85a6bf990a5dd7b0a32985b3fd4edbc65bfcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
