{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 256\n",
    "C = 4\n",
    "D = 17\n",
    "H = 64\n",
    "W = 64\n",
    "class BiLSTM2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn_v = nn.GRU(C, D, \n",
    "                            num_layers=1, \n",
    "                            batch_first=True, \n",
    "                            bias=True,\n",
    "                            bidirectional=True)\n",
    "        self.rnn_h = nn.GRU(C, D, \n",
    "                            num_layers=1, \n",
    "                            batch_first=True, \n",
    "                            bias=True,\n",
    "                            bidirectional=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        v, _ = self.rnn_v(x.permute(0, 2, 1, 3).reshape(-1, H, C))\n",
    "        v = v.reshape(B, W, H, -1).permute(0, 2, 1, 3)\n",
    "        h, _ = self.rnn_h(x.reshape(-1, W, C))\n",
    "        h = h.reshape(B, H, W, -1)\n",
    "        x = torch.cat([v, h], dim=-1)\n",
    "        print(x.shape)\n",
    "        x = x.reshape(*x.shape[:-1], C, D)\n",
    "        print(x.shape)\n",
    "        # x = x.mean(dim=-1, keepdim=True)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "net = BiLSTM2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 64, 64, 4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_obs = torch.randn([256, 64, 64, 4])\n",
    "batched_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 64, 64, 68])\n",
      "torch.Size([256, 64, 64, 4, 17])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 64, 64, 4, 17])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = net(batched_obs)\n",
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmm_input(b_weight, b_input):\n",
    "    bmm = torch.einsum('bhwcf, bhwc -> bf', b_weight, b_input)\n",
    "    return bmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = bmm_input(weight, batched_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 17])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 560.6110,  284.6977,  679.4728,  ...,  146.1381,   12.0559,\n",
       "         -264.9316],\n",
       "        [ 566.2153,  252.6550,  710.1396,  ...,  147.5023,   77.9313,\n",
       "         -299.2885],\n",
       "        [ 583.9216,  228.4675,  647.5270,  ...,  136.6174,   93.6364,\n",
       "         -342.7438],\n",
       "        ...,\n",
       "        [ 577.6134,  269.4700,  667.4359,  ...,  140.9128,   48.1660,\n",
       "         -271.1786],\n",
       "        [ 540.0983,  254.1015,  709.4675,  ...,  215.7526,   85.6181,\n",
       "         -318.4952],\n",
       "        [ 537.0328,  281.9046,  760.7954,  ...,  127.5297,   52.0008,\n",
       "         -291.7527]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = hidden / np.sqrt(W*H*D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1245,  1.0789,  2.5749,  ...,  0.5538,  0.0457, -1.0040],\n",
       "        [ 2.1457,  0.9575,  2.6912,  ...,  0.5590,  0.2953, -1.1342],\n",
       "        [ 2.2128,  0.8658,  2.4539,  ...,  0.5177,  0.3548, -1.2989],\n",
       "        ...,\n",
       "        [ 2.1889,  1.0212,  2.5293,  ...,  0.5340,  0.1825, -1.0277],\n",
       "        [ 2.0468,  0.9629,  2.6886,  ...,  0.8176,  0.3245, -1.2070],\n",
       "        [ 2.0352,  1.0683,  2.8831,  ...,  0.4833,  0.1971, -1.1056]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 256\n",
    "C = 4\n",
    "D = 17\n",
    "H = 64\n",
    "W = 64\n",
    "class BiLSTM2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn_c = nn.GRU(1, D, \n",
    "                            num_layers=1, \n",
    "                            batch_first=True, \n",
    "                            bias=True,\n",
    "                            bidirectional=True)\n",
    "        self.rnn_v = nn.GRU(D, D, \n",
    "                            num_layers=1, \n",
    "                            batch_first=True, \n",
    "                            bias=True,\n",
    "                            bidirectional=True)\n",
    "        self.rnn_h = nn.GRU(D, D, \n",
    "                            num_layers=1, \n",
    "                            batch_first=True, \n",
    "                            bias=True,\n",
    "                            bidirectional=True)\n",
    "    \n",
    "    def forward(self, x, H, W, C):\n",
    "        x, _ = self.rnn_c(x.permute(0, 3, 2, 1).reshape(-1, C, 1))\n",
    "        print(x.shape)\n",
    "        x = x.reshape(-1, H, W, 1)\n",
    "        print(x.shape)\n",
    "        v, _ = self.rnn_v(x.permute(0, 2, 1, 3).reshape(-1, H, D))\n",
    "        v = v.reshape(B, W, H, -1).permute(0, 2, 1, 3)\n",
    "        h, _ = self.rnn_h(x.reshape(-1, W, D))\n",
    "        h = h.reshape(B, H, W, -1)\n",
    "        x = torch.cat([v, h], dim=-1)\n",
    "        print(x.shape)\n",
    "        x = x.reshape(*x.shape[:-1], 1, -1)\n",
    "        print(x.shape)\n",
    "        # x = x.mean(dim=-1, keepdim=True)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "net = BiLSTM2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 64, 64, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_obs = torch.randn([256, 64, 64, 4])\n",
    "batched_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1048576, 4, 34])\n",
      "torch.Size([34816, 64, 64, 1])\n",
      "torch.Size([256, 64, 64, 544])\n",
      "torch.Size([256, 64, 64, 1, 544])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 64, 64, 1, 544])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = net(batched_obs, 64, 64, 4)\n",
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "570425344 / 256 / 64 / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17 * 17 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7ee91ee17640122f02738ad5b71799946a97252eaa170610250681b99b684d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
